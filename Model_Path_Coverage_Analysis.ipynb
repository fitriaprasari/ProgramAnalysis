{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fitriaprasari/ProgramAnalysis/blob/main/Model_Path_Coverage_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ── 1. Sensor ────────────────────────────────────────────────────────────\n",
        "# Taken from your notebook\n",
        "class TransactionSensor:\n",
        "    def __init__(self, path: str):\n",
        "        self.path = path\n",
        "\n",
        "    def stream(self) -> pd.DataFrame:\n",
        "        print(f\"[Sensor] Reading file {self.path} …\")\n",
        "        df = pd.read_csv(self.path)\n",
        "        print(f\"[Sensor] Loaded {len(df)} rows × {df.shape[1]} cols\\n\")\n",
        "        return df\n",
        "\n",
        "# ── 2. Perception ────────────────────────────────────────────────────────\n",
        "# Taken from your notebook\n",
        "class PerceptionModule:\n",
        "    def __init__(self, num_raw, cat_cols):\n",
        "        self.num_raw  = num_raw\n",
        "        self.cat_cols = cat_cols\n",
        "        self.scaler   = StandardScaler()\n",
        "        print(\"[Perception] Initializing StandardScaler and OneHotEncoder+PCA pipeline\")\n",
        "\n",
        "        self.prep = ColumnTransformer([\n",
        "            ('num', 'passthrough', [c + '_z' for c in num_raw]),\n",
        "            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols)\n",
        "        ])\n",
        "        self.pca  = PCA(n_components=0.95, random_state=42)\n",
        "        self.pipe = Pipeline([('prep', self.prep), ('pca', self.pca)])\n",
        "\n",
        "    def fit(self, X: pd.DataFrame):\n",
        "        print(\"[Perception] Fitting scaler on numeric columns:\")\n",
        "        X_num = X[self.num_raw]\n",
        "        X_z   = self.scaler.fit_transform(X_num)\n",
        "        for i, c in enumerate(self.num_raw):\n",
        "            X[c + '_z'] = X_z[:, i]\n",
        "        print(\"\\n[Perception] Fitting PCA on preprocessed data…\")\n",
        "        self.pipe.fit(X)\n",
        "        cumvar = np.cumsum(self.pca.explained_variance_ratio_)\n",
        "        print(f\"  • PCA kept {self.pca.n_components_} components\")\n",
        "        print(f\"  • Cumulative variance explained: {cumvar[-1]:.3f}\\n\")\n",
        "\n",
        "    def transform(self, X: pd.DataFrame) -> np.ndarray:\n",
        "        print(\"[Perception] Transforming data through PCA pipeline…\")\n",
        "        X_num = X[self.num_raw]\n",
        "        X_z   = self.scaler.transform(X_num)\n",
        "        for i, c in enumerate(self.num_raw):\n",
        "            X[c + '_z'] = X_z[:, i]\n",
        "        X_pca = self.pipe.transform(X)\n",
        "        print(f\"  • Output shape: {X_pca.shape}\")\n",
        "        return X_pca\n",
        "\n",
        "# ── 3. CognitiveCore – Decision Tree ────────────────────────────────────\n",
        "# Taken from your notebook\n",
        "class TreeCore:\n",
        "    def __init__(self):\n",
        "        print(\"[Cognition:Tree] Initializing Decision Tree model\")\n",
        "        # IMPORTANT: We are not limiting tree depth to see all paths\n",
        "        self.clf = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        print(\"[Cognition:Tree] Training Decision Tree…\")\n",
        "        self.clf.fit(X, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        print(\"[Cognition:Tree] Predicting with Decision Tree…\")\n",
        "        return self.clf.predict(X)\n",
        "\n",
        "    def score(self, X, y):\n",
        "        acc = accuracy_score(y, self.predict(X))\n",
        "        print(f\"[Cognition:Tree] Accuracy = {acc:.3f}\\n\")\n",
        "        return acc\n",
        "\n",
        "# ── 4. Main Flow (Adapted for Analysis) ──────────────────────────────\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # 4.1 Setup: Sensor, Split, Perception (as in notebook)\n",
        "    sensor = TransactionSensor(\"data_labeled.csv\")\n",
        "    df     = sensor.stream()\n",
        "\n",
        "    y     = df['Class']\n",
        "    Xraw  = df.drop(columns='Class')\n",
        "\n",
        "    num_raw  = ['TransactionAmount','AccountBalance','TransactionDuration','CustomerAge','LoginAttempts']\n",
        "    cat_cols = ['Location','Channel']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        Xraw, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "    vision = PerceptionModule(num_raw, cat_cols)\n",
        "    vision.fit(X_train)\n",
        "    X_train_pca = vision.transform(X_train)\n",
        "    X_test_pca  = vision.transform(X_test)\n",
        "\n",
        "    # 4.2 Train Model (as in notebook)\n",
        "    tree_core = TreeCore()\n",
        "    tree_core.fit(X_train_pca, y_train)\n",
        "\n",
        "    # 4.3 PREDICT (for later validation)\n",
        "    y_pred_dt = tree_core.predict(X_test_pca)\n",
        "    print(\"\\n[Main] Model standard prediction complete.\\n\")\n",
        "\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # NEW SECTION: SCOPE 1 - MODEL LOGIC VERIFICATION (MODEL COVERAGE)\n",
        "    # ----------------------------------------------------------------------\n",
        "    print(\"=\"*60)\n",
        "    print(\"SCOPE 1: MODEL LOGIC VERIFICATION (MODEL COVERAGE)\")\n",
        "    print(\"Focus: Decision Tree internal paths (rules)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    fitted_model = tree_core.clf\n",
        "    tree_structure = fitted_model.tree_\n",
        "\n",
        "    # Step 1: Find all possible paths (rules) within the model\n",
        "    # A \"path\" is represented by a \"leaf node\".\n",
        "    # A node is a leaf if `children_left` and `children_right` == -1.\n",
        "\n",
        "    children_left = tree_structure.children_left\n",
        "    children_right = tree_structure.children_right\n",
        "\n",
        "    total_leaf_nodes = set()\n",
        "    for i in range(tree_structure.node_count):\n",
        "        if children_left[i] == -1 and children_right[i] == -1:\n",
        "            total_leaf_nodes.add(i)\n",
        "\n",
        "    total_paths_in_model = len(total_leaf_nodes)\n",
        "\n",
        "    if total_paths_in_model == 0:\n",
        "        print(\"Error: Decision Tree model not trained or has no leaves.\")\n",
        "    else:\n",
        "        print(f\"Model Analysis: The trained Decision Tree has {total_paths_in_model} unique 'rules' (paths to leaves).\")\n",
        "\n",
        "        # Step 2: Find all paths EXECUTED by the test set (X_test_pca)\n",
        "        # The .apply() method returns the ID of the leaf node for each sample.\n",
        "\n",
        "        covered_leaf_ids_array = fitted_model.apply(X_test_pca)\n",
        "        covered_leaf_nodes = set(covered_leaf_ids_array)\n",
        "\n",
        "        covered_paths_count = len(covered_leaf_nodes)\n",
        "\n",
        "        print(f\"Test Set Analysis: The test set (X_test_pca) executed {covered_paths_count} out of {total_paths_in_model} of those rules.\")\n",
        "\n",
        "        # Step 3: Calculate Model Path Coverage\n",
        "        coverage_percentage = (covered_paths_count / total_paths_in_model) * 100\n",
        "\n",
        "        print(\"\\n--- Model Path Coverage Results ---\")\n",
        "        print(f\"  Total Rules (Paths) in Model: {total_paths_in_model}\")\n",
        "        print(f\"  Covered Rules (by Test Set): {covered_paths_count}\")\n",
        "        print(f\"  Model Path Coverage: {coverage_percentage:.2f}%\")\n",
        "\n",
        "        # Step 4: Identify UNCOVERED Rules (Paths)\n",
        "        # This is your main goal: identifying untried paths\n",
        "        uncovered_leaf_nodes = total_leaf_nodes - covered_leaf_nodes\n",
        "        uncovered_count = len(uncovered_leaf_nodes)\n",
        "\n",
        "        print(f\"\\nObjective Identification: Found {uncovered_count} untested paths/rules.\")\n",
        "\n",
        "        if uncovered_count > 0:\n",
        "            print(\"  The following are the leaf node IDs (representing rules) that were NOT executed by the test set:\")\n",
        "            # Display only the first 20 for brevity\n",
        "            print(f\"  {list(uncovered_leaf_nodes)[:20]}...\")\n",
        "        else:\n",
        "            print(\"  CONGRATULATIONS! All paths in the Decision Tree have been successfully covered by the test set.\")\n",
        "\n",
        "    print(\"=\"*60)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Sensor] Reading file data_labeled.csv …\n",
            "[Sensor] Loaded 2512 rows × 17 cols\n",
            "\n",
            "[Perception] Initializing StandardScaler and OneHotEncoder+PCA pipeline\n",
            "[Perception] Fitting scaler on numeric columns:\n",
            "\n",
            "[Perception] Fitting PCA on preprocessed data…\n",
            "  • PCA kept 49 components\n",
            "  • Cumulative variance explained: 0.950\n",
            "\n",
            "[Perception] Transforming data through PCA pipeline…\n",
            "  • Output shape: (2009, 49)\n",
            "[Perception] Transforming data through PCA pipeline…\n",
            "  • Output shape: (503, 49)\n",
            "[Cognition:Tree] Initializing Decision Tree model\n",
            "[Cognition:Tree] Training Decision Tree…\n",
            "[Cognition:Tree] Predicting with Decision Tree…\n",
            "\n",
            "[Main] Model standard prediction complete.\n",
            "\n",
            "============================================================\n",
            "SCOPE 1: MODEL LOGIC VERIFICATION (MODEL COVERAGE)\n",
            "Focus: Decision Tree internal paths (rules)\n",
            "============================================================\n",
            "Model Analysis: The trained Decision Tree has 64 unique 'rules' (paths to leaves).\n",
            "Test Set Analysis: The test set (X_test_pca) executed 36 out of 64 of those rules.\n",
            "\n",
            "--- Model Path Coverage Results ---\n",
            "  Total Rules (Paths) in Model: 64\n",
            "  Covered Rules (by Test Set): 36\n",
            "  Model Path Coverage: 56.25%\n",
            "\n",
            "Objective Identification: Found 28 untested paths/rules.\n",
            "  The following are the leaf node IDs (representing rules) that were NOT executed by the test set:\n",
            "  [5, 6, 7, 9, 11, 26, 36, 41, 52, 54, 55, 57, 58, 68, 73, 74, 79, 83, 85, 98]...\n",
            "============================================================\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3RORLY7yOON",
        "outputId": "86ca57fe-f59f-4fa1-b8cc-c51d13f7c900"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_rule_for_leaf(tree_structure, leaf_id, feature_names):\n",
        "    \"\"\"\n",
        "    Reconstructs the rule leading to a specific leaf node in a Decision Tree.\n",
        "\n",
        "    Args:\n",
        "        tree_structure: The sklearn.tree._tree.Tree object (e.g., fitted_model.tree_).\n",
        "        leaf_id: The ID of the leaf node.\n",
        "        feature_names: A list of feature names corresponding to the feature indices.\n",
        "\n",
        "    Returns:\n",
        "        A string representing the rule, or an error message if the node is not a leaf\n",
        "        or not found.\n",
        "    \"\"\"\n",
        "    children_left = tree_structure.children_left\n",
        "    children_right = tree_structure.children_right\n",
        "    feature = tree_structure.feature\n",
        "    threshold = tree_structure.threshold\n",
        "    value = tree_structure.value\n",
        "    n_node_samples = tree_structure.n_node_samples\n",
        "\n",
        "    if children_left[leaf_id] != -1 or children_right[leaf_id] != -1:\n",
        "        return f\"Node {leaf_id} is not a leaf node.\"\n",
        "\n",
        "    # Recursively find the path from the root to the leaf\n",
        "    full_path_nodes = []\n",
        "    def find_path(node_id, current_path):\n",
        "        if node_id == -1:\n",
        "            return False\n",
        "\n",
        "        current_path.append(node_id)\n",
        "\n",
        "        if node_id == leaf_id:\n",
        "            return True\n",
        "\n",
        "        if children_left[node_id] != -1:\n",
        "            if find_path(children_left[node_id], current_path):\n",
        "                return True\n",
        "\n",
        "        if children_right[node_id] != -1:\n",
        "            if find_path(children_right[node_id], current_path):\n",
        "                return True\n",
        "\n",
        "        current_path.pop() # Backtrack\n",
        "        return False\n",
        "\n",
        "    find_path(0, full_path_nodes)\n",
        "\n",
        "    if not full_path_nodes or full_path_nodes[-1] != leaf_id:\n",
        "        return f\"Could not find path to node {leaf_id}.\"\n",
        "\n",
        "    rules = []\n",
        "    for i in range(len(full_path_nodes) - 1):\n",
        "        node = full_path_nodes[i]\n",
        "        child = full_path_nodes[i+1]\n",
        "\n",
        "        feat_idx = feature[node]\n",
        "        if feat_idx == -2: # Should not happen for internal nodes\n",
        "            continue\n",
        "\n",
        "        feat_name = feature_names[feat_idx]\n",
        "        thresh = threshold[node]\n",
        "\n",
        "        if children_left[node] == child:\n",
        "            rules.append(f\"{feat_name} <= {thresh:.4f}\")\n",
        "        elif children_right[node] == child:\n",
        "            rules.append(f\"{feat_name} > {thresh:.4f}\")\n",
        "\n",
        "    # Add leaf node prediction\n",
        "    values_at_leaf = value[leaf_id][0]\n",
        "    predicted_class = np.argmax(values_at_leaf)\n",
        "    class_counts = f\"Class 0: {int(values_at_leaf[0])}, Class 1: {int(values_at_leaf[1])}\"\n",
        "\n",
        "    rule_string = \" AND \".join(rules)\n",
        "    rule_string += f\" -> Predict Class {predicted_class} (samples: {n_node_samples[leaf_id]}, {class_counts})\"\n",
        "\n",
        "    return rule_string\n",
        "\n",
        "# Generate feature names for PCA components (assuming X_train_pca is available)\n",
        "pca_feature_names = [f\"component_{i}\" for i in range(X_train_pca.shape[1])]\n",
        "\n",
        "# Get the first uncovered leaf node ID (assuming 'uncovered_leaf_nodes' is available)\n",
        "first_uncovered_node_id = list(uncovered_leaf_nodes)[0] if uncovered_leaf_nodes else None\n",
        "\n",
        "if first_uncovered_node_id is not None:\n",
        "    print(f\"The rule for uncovered leaf node {first_uncovered_node_id} is:\")\n",
        "    rule_for_node = get_rule_for_leaf(fitted_model.tree_, first_uncovered_node_id, pca_feature_names)\n",
        "    print(rule_for_node)\n",
        "else:\n",
        "    print(\"No uncovered leaf nodes were found to display rules for.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SMxiQBwN1ZP",
        "outputId": "ce5e341b-2646-4116-c6c6-70a61080facf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The rule for uncovered leaf node 5 is:\n",
            "component_0 <= -0.2570 AND component_2 <= -0.4838 AND component_0 <= -1.7783 AND component_4 <= 0.1056 AND component_31 <= 0.0054 -> Predict Class 1 (samples: 3, Class 0: 0, Class 1: 1)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}